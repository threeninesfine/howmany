---
title: "Tabulating Results of Simulation Study"
author: "Michael Flanagin  \\ flanna@uw.edu"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
classoption: portrait
header-includes:
  - \usepackage[table]{xcolor}
  - \usepackage{booktabs}
  - \usepackage{caption}
  - \usepackage{longtable}
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    number_sections: yes
  html_document:
    fig_caption: yes
    force_captions: yes
    highlight: pygments
    number_sections: yes
    theme: cerulean
csl: mee.csl
---
\captionsetup[table]{ labelformat = empty } <!-- disable auto table numbering with kable -->

```{r setup, eval = FALSE, echo=FALSE}
  devtools::install_github("cboettig/knitcitations@v1")
  library(knitcitations); cleanbib()
  cite_options(citation_format = "pandoc", check.entries=FALSE)
  library(bibtex)
```

```{r globalopts, cache = TRUE, warning = FALSE, echo = FALSE}
# Load libraries necessary for functions used in this document
library('knitr')
library('xtable')
library('kableExtra')  # for additional table formatting
# library('dplyr')  # for table coloring
# Set global chunk options
opts_chunk$set(echo = FALSE,     # do NOT repeat code in final document
               message = FALSE,  # do NOT print R messages in document
               warning = FALSE,  # do NOT print warnings
               self.contained = TRUE ) # do NOT call other .Rnw docs! 
round_digits <- 3  # digits to round to when presenting results
options( knitr.table.format = "latex")  # guarantees 'kableExtra' formatting handled properly
options( scipen = 999 )
#         knitr.kable.na = " - ", 
#         scipen = 10)  # replaces NA entries with ' - ' in kable output
#         scipen = 999 )  # effectively disables scientific notation
setwd(getwd())  # set working directory to current file path.

# function kable_booktabs_linesep()
kable_booktabs_linesep <- function( nlines = 6 ){
  #' input: 
  #'   nlines := number of lines per block of table rows
  #' output:
  #'   [character] linespace string to pass to kable()
  #' example:
  #'   kable( foo_table, booktabs = TRUE, linesep = kable_booktabs_linesep( nlines = 6) )
  return(c(rep( '', nlines - 1 ), "\\addlinespace"))
}
```

```{r load_datasets, cache = TRUE, echo = FALSE, message = FALSE}
datadir_path <- "/Users/Moschops/Documents/MSThesis/results/"
tmpdir_path <- "/Users/Moschops/Documents/MSThesis/results/output_2018-08-28_15-07/"
#' [ Batch 1 of 4: binary Y, binary X ] 
metrics_batch1 <- read.csv(paste0( datadir_path, "metrics-alloc-simulation-batch-1-of-4.csv" ))
#' [ Batch 2 of 4: binary Y, continuous X ] 
metrics_batch2 <- read.csv(paste0( datadir_path, "metrics-alloc-simulation-batch-2-of-4.csv" ))
#' [ Batch 3 of 4: continuous Y, binary X ] 
# metrics_batch3 <- read.csv(paste0( datadir_path, "metrics-alloc-simulation-batch-3-of-4.csv" ))
metrics_batch3 <- read.csv(paste0( tmpdir_path, "metrics-alloc-simulation-batch-3-of-4.csv" ))
#' [ Batch 4 of 4: continuous Y, continuous X ] 
metrics_batch4 <- read.csv(paste0( datadir_path, "metrics-alloc-simulation-batch-4-of-4.csv" ))

#' [ Batch 1 of 4: binary Y, binary X -- subsetted on simulations without complete/quasi separation ]
metrics_batch1_sub <- read.csv(paste0( datadir_path, "metrics-subset-alloc-simulation-batch-1-of-4.csv" ))
#' [ Batch 2 of 4: binary Y, continuous X -- subsetted on simulations without complete/quasi separation ]
metrics_batch2_sub <- read.csv(paste0( datadir_path, "metrics-subset-alloc-simulation-batch-2-of-4.csv" ))

```

# Introduction
Simulation results are presented by outcome and predictor variable type pairs (binary, continuous).

Each outcome/predictor pair, we present tables for:

* coverage probability, 
* bias, and 
* power.

Simulation conditions are ordered by:

* sample size (n), 
* marginal outcome prevalence Pr( Y ),
* prognostic factor prevalence Pr( X ),
* treatment effect size (exp( bZ )), and
* prognostic factor effect size (bX).

Binary outcomes are fit with a Binomial generalized linear model, continuous outomes with an ordinary linear model.

Resulting estimates of treatment effect are adjusted ('adj') or unadjusted ('unadj') for prognostic factors used in the allocation method.

Three allocation methods are compared to each other:

* Complete randomization (CR),
* Stratified block randomization (SBR), with a block size of 4,
* Covariate adaptive allocation (CAA), with a maximum imbalance of 2 and an allocation biasing probability of 0.70.

The analysis method for uncertainty estimates is either:

* Model-based (using p-values from relevant t-statistics), or
* Rerandomization-based, with 500 rerandomized treatment allocations performed per simulation draw.

----------
## Modifications
+ [ table 1a: coverage ] Under `Rerandomization`:`CAA`:`adj` rows 40, 47, 48: coverages near 0
+ [ tables (bias) ] Report median bias
+ [ Batch 2 ] `CAA_rerand_adj` NA estimates 
+ [ Table 2f ] `CR` identical to `CAA_model`, both unadjusted and adjusted
+ [ Table 3a ] `CAA_model_adj` estimates all 1 or 0. Does this mean they haven't been run?
+ [ Table 3a: coverage ] Duplicated estimates in each row 
+ [ Table 3b: bias ] Duplicated estimates in pairs for each method
+ [ Table 3c: power ] Duplicated estimates in pairs for each method

## Observations
### Table 1a: coverage

+ Unadjusted methods have greater coverage than adjusted methods
+ for low outcome prevalence cases, coverage close to 1.000
+ `CAA_rerand_adj` has coverage greater than `CAA_model_adj`
+ `CAA_rerand_adj` has poor performance when `bZ` is 3

### Table 1b: bias

+ Low outcome prevalence and high treatment effect, large positive bias in all methods
+ bias approaches 0 when sample size is increased or outcome prevalence increases
+ `CAA_rerand_adj` has same bias as `CAA_model_adj` (rerandomization has no effect on bias)

### Table 1c: power

+ Adjusted methods have greater power than unadjusted estimates (as anticipated)
+ CR methods go against this trend (unadjusted has slightly greater power)
+ Power increases with `bZ`
+ Power increases with `bX` in all methods
+ `CAA_rerand_adj` is consistently more powerful than `CAA_model_adj`

### Table 1d: coverage (subsetted)

+ foo

### Table 1e: bias (subsetted)

+ bar

### Table 1f: power (subsetted)

+ baz

```{r assert_that, cache = TRUE, echo = FALSE}
#' [ assert_that( expr, errmsg ) returns `errmsg` if expr is NOT true ]
assert_that <- function( expr, errmsg ){
  if( !all( expr ) )
    stop( errmsg, call. = FALSE )
}

#' [ get_nsim_col() computes mean number of simulations and returns the proportion of included sims ]
#' [ if `include_percentage` is TRUE. ]
get_nsim_col <- function( tbl_nsim, include_percentage = TRUE ){
  method_cols <- grep( "un|adj$", names( tbl_nsim ), value = FALSE ) #' [ find all columns with metrics ]
  tbl_nsim_mean <- apply( tbl_nsim[, method_cols ], 1, function(.row){ round(mean( .row ))} )
  tbl_proportion_sims <- paste0(" (",round( tbl_nsim_mean / 5010 * 100, 1 ), "%)")
  if( include_percentage ){
    return(mapply( paste0, tbl_nsim_mean, tbl_proportion_sims, MoreArgs = list(collapse = "") ))
  }else{
    return( tbl_nsim_mean )
  }
}

#' [ replace_large_values( value, threshold) replaces large values with strings: ]
#' [ returns ">/<`threshold` if value is large, `value` otherwise. ]
replace_large_value <- function( value, threshold = 1000 ){
  if( is.na( value ) ){
    return( "NA" )
  }else if( value > threshold ){
    return( paste0(">", threshold) )
  }else if( value < - threshold ){
    return( paste0("<", threshold) )
  }else{
    return( value )
  }
}
#' [ replace_values() is a vectorized version of replace_large_value() ]
replace_values <- Vectorize( replace_large_value )

```

```{r summary_table, cache = FALSE, echo = FALSE}
make_summary_table <- function( metric_df,
                                metric = "coverage",
                                get_adj_ests = TRUE,
                                round_digits = 3,
                                parameter_names = c( "modelno","trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size", 
                                                "outcome_marginal_prevalence", "prognostic_factor_prevalence" ),
                                table_colnames = c("CR", "SBR", "CAA_model", "CAA_rerand","modelno", "n", "bZ", "bX", "Pr( Y )", "Pr( X )"),
                                return_row_indices = FALSE,
                                verbose = FALSE )
{
  #' [1] Get row indices corresponding to alloc method, rerandomization type, and adjustment method
  row_indices <- list();
  row_indices[["CR"]] <- with( metric_df, which( alloc_method == "CR" & rerandomized == 0 & adjusted == get_adj_ests ));
  row_indices[["SBR"]] <- with( metric_df, which( alloc_method == "SBR" & rerandomized == 0 & adjusted == get_adj_ests ));
  row_indices[["CAA_model"]] <- with( metric_df, which( alloc_method == "CAA-MI-2-PBA-0.70" & rerandomized == 0 & adjusted == get_adj_ests ));
  row_indices[["CAA_rerand"]] <- with( metric_df, which( alloc_method == "CAA-MI-2-PBA-0.70" & rerandomized == 1 & adjusted == get_adj_ests ));

  #' [2] By (alloc_method, rerandomized, adjusted), view how many rows were selected.
  row_lengths <- sapply( row_indices, function( .indices ){ length( .indices ) })
  # Given variable row lengths, throw errors (or pad table)
  row_lengths_table <- table( row_lengths )
  if(length( row_lengths_table ) > 1 & verbose ){
    cat("WARNING: method row lengths are not identical! \nWish this warning message was more detailed...\n")
  }

  #' [3] Get statistics, round to 'round_digits'. Also get NA values.
  metrics_by_method <- lapply( row_indices, function( .indices ){
    if( length( .indices ) == 0 ){ # if no rows selected, return all NAs
      return(rep( NA, times = max( row_lengths ))) 
    }else{
      # if metric == 'power', select 'power.rerand' or 'power.pvalue' 
      #   depending on if rerandomized == TRUE or FALSE, respectively.
      if( metric == "power" ){ 
        if(any( metric_df[ .indices, "rerandomized" ] == 1 )){
          return(round( metric_df[ .indices, "power.rerand" ], round_digits ))
        }else{
          return(round( metric_df[ .indices, "power.pvalue" ], round_digits ))
        }
      }else{
        return(round( metric_df[ .indices, metric ], round_digits ))
      }
    }})
  metrics_table <- do.call( cbind, metrics_by_method )

  #' [4] Get parameters corresponding to each model.
  model_params_table <- metric_df[ row_indices[["CR"]], parameter_names ];
  
  #' [5] Piece all method components together and (2) rename column names.
  output_table <- cbind( metrics_table, model_params_table );
  dimnames( output_table )[[2]] <- table_colnames;
  
  #' [6] For diagnostics: return row indices?
  if( !return_row_indices ){
    return( summary = output_table )
  }else{
    return(list( summary = output_table,
                 row_indices = row_indices ))
  }
}
```

```{r summary_tables_big_and_sorted, cache = TRUE, echo = FALSE}
#' [ make_summary_tables_adj_and_unadj_sorted() ]
#' use: [1] makes summary tables (with adjusted and unadjusted estimates side by side)
#'      [2] sorts by sort_by_vars.
make_summary_tables_adj_and_unadj_sorted <- 
  function( metric_df,
            metric,
            round_digits,
            parameter_names,
            table_colnames = c("CR", "SBR", "CAA_model", "CAA_rerand", "n", "bZ", "bX", "Pr( Y )", "Pr( X )"),
            sort_by_vars = c("n", "Pr( Y )", "Pr( X )", "bZ", "bX") )
{
  #' [0] Assertions
  assert_that( sort_by_vars %in% table_colnames, 
               errmsg = "All variables in `sort_by_vars` must be in `table_colnames`." )
  assert_that( parameter_names %in% names( metric_df ), 
               errmsg = "All variables in `parameter_names` must be in data.frame `metric_df`." )
    
  #' [1] Get adjusted and unadjusted summary tables
  outdf_adj <- make_summary_table( metric_df = metric_df, metric = metric, get_adj_ests = TRUE, round_digits = round_digits,
                                   parameter_names = parameter_names, table_colnames = table_colnames )
  outdf_un <- make_summary_table( metric_df = metric_df, metric = metric, get_adj_ests = FALSE, round_digits = round_digits,
                                   parameter_names = parameter_names, table_colnames = table_colnames )
  
  #' [2] Sort rows by variables: 'sort_by_vars'
  col_indices_sort_variables <- sapply( sort_by_vars, function( .varname ){ which( table_colnames == .varname ) })
  row_indices_sorted <- do.call( order, outdf_adj[, col_indices_sort_variables ] )
  
  #' [3] Make table of [{model parameters, 'adjusted':'unadjusted' ests by randomization type.}]
  outdf_all <- cbind( outdf_adj[, col_indices_sort_variables ],
                      CR_adj = outdf_adj$CR, CR_un = outdf_un$CR,
                      SBR_adj = outdf_adj$SBR, SBR_un = outdf_un$SBR,
                      CAA_model_adj = outdf_adj$CAA_model, CAA_model_un = outdf_un$CAA_model,
                      CAA_rerand_adj = outdf_adj$CAA_rerand, CAA_rerand_un = outdf_un$CAA_rerand )
  #' [3b] add `modelno` to RHS if included in `table_colnames`.
  if( "modelno" %in% table_colnames ){
    outdf_all <- cbind( modelno = outdf_adj$modelno, outdf_all )
  }
  
  #' [4] Exclude certain parameters. 
  col_names_to_exclude <- c("CAA_rerand_un") # c("modelno", "CAA_rerand_un") 
  col_indices_to_exclude <- which( dimnames( outdf_all)[[2]] %in% col_names_to_exclude )
  
  #' [5] Return estimates in sorted order, excluding variables in `col_indices_to_exclude`.
  return( outdf_all[ row_indices_sorted, - col_indices_to_exclude ] )
}
```

```{r summary_table_wrapper_functions, cache = TRUE, echo = FALSE}
#' [ Define wrapper functions with defaults for 'parameter_names', 'table_colnames', and 'sort_by_vars' ]
batch1_make_summary_tables <- function( metric_df, metric, include_modelno = FALSE, sort_by_vars = c("n", "Pr( Y )", "Pr( X )", "bZ", "bX")){
  if( include_modelno ){
    .parameter_names <- c( "modelno","trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size", 
                                                "outcome_marginal_prevalence", "prognostic_factor_prevalence" );
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand","modelno", "n", "bZ", "bX", "Pr( Y )", "Pr( X )");
  }else{
    .parameter_names <- c( "trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size", 
                                                "outcome_marginal_prevalence", "prognostic_factor_prevalence" );
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand", "n", "bZ", "bX", "Pr( Y )", "Pr( X )");
  }
  return( make_summary_tables_adj_and_unadj_sorted(
    metric_df = metric_df,
    metric = metric,
    round_digits = 3,
    parameter_names =  .parameter_names,
    table_colnames = .col_names,
    sort_by_vars = sort_by_vars))
}

batch2_make_summary_tables <- function( metric_df, metric, include_modelno = FALSE, sort_by_vars = c("n", "Pr( Y )", "bZ", "bX")){
  if( include_modelno ){
    .parameter_names <- c( "modelno","trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size", 
                                                "outcome_marginal_prevalence" )
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand","modelno", "n", "bZ", "bX", "Pr( Y )")
  }else{
    .parameter_names <- c( "trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size", 
                                                "outcome_marginal_prevalence" )
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand", "n", "bZ", "bX", "Pr( Y )")
  }
  return( make_summary_tables_adj_and_unadj_sorted(
    metric_df = metric_df,
    metric = metric,
    round_digits = 3,
    parameter_names =  .parameter_names,
    table_colnames = col_names,
    sort_by_vars = sort_by_vars))
}

batch3_make_summary_tables <- function( metric_df, metric, include_modelno = FALSE, sort_by_vars = c("n", "Pr( X )", "bZ", "bX")){
  if( include_modelno ){
    .parameter_names <- c( "modelno","trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size",
                          "prognostic_factor_prevalence" )
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand","modelno", "n", "bZ", "bX", "Pr( X )")
  }else{
    .parameter_names <- c( "trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size",
                          "prognostic_factor_prevalence" )
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand", "n", "bZ", "bX", "Pr( X )")
  }
  return( make_summary_tables_adj_and_unadj_sorted(
    metric_df = metric_df,
    metric = metric,
    round_digits = 3,
    parameter_names =  .parameter_names,
    table_colnames = .col_names,
    sort_by_vars = sort_by_vars))
}

batch4_make_summary_tables <- function( metric_df, metric, include_modelno = FALSE, sort_by_vars = c("n", "bZ", "bX")){
  if( include_modelno ){
    .parameter_names <- c( "modelno","trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size" );
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand","modelno", "n", "bZ", "bX")
  }else{
    .parameter_names <- c( "trial_size", "treatment_assignment_effect_size", "prognostic_factor_effect_size" );
    .col_names = c("CR", "SBR", "CAA_model", "CAA_rerand", "n", "bZ", "bX")
  }
  return( make_summary_tables_adj_and_unadj_sorted(
    metric_df = metric_df,
    metric = metric,
    round_digits = 3,
    parameter_names =  .parameter_names,
    table_colnames = .col_names,
    sort_by_vars = sort_by_vars))
}
```

```{r batch-1-tables-unformatted, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
batch1_subset_tables <- function( metric_df, metric ){
  #' [ 1. make summary tables ]
  batch1_tbl <- batch1_make_summary_tables( metric_df = metric_df, metric = metric)
  #' [ 2. compute average `nsims` and modify column names to include it. ]
  nsims_batch1_subset <- batch1_make_summary_tables( metric_df = metric_df, metric = "nsim")
  batch1_nsim_col <- get_nsim_col( tbl_nsim = nsims_batch1_subset )
  return(cbind.data.frame( avg_nsim = batch1_nsim_col, batch1_tbl ))
}

batch2_subset_tables <- function( metric_df, metric ){
  #' [ 1. make summary tables ]
  batch2_tbl <- batch2_make_summary_tables( metric_df = metric_df, metric = metric)
  #' [ 2. compute average `nsims` and modify column names to include it. ]
  nsims_batch2_subset <- batch1_make_summary_tables( metric_df = metric_df, metric = "nsim")
  batch2_nsim_col <- get_nsim_col( tbl_nsim = nsims_batch2_subset )
  return(cbind.data.frame( batch2_nsim_col, batch2_tbl ))
}
```

```{r batch-1-tables-unformatted, cache = TRUE, echo = FALSE, message = FALSE, warning = FALSE}



#' [ Batch 1: Binary Y, binary X ]
tbl1a <- batch1_make_summary_tables( metric_df = metrics_batch1, metric = "coverage")
tbl1b <- batch1_make_summary_tables( metric_df = metrics_batch1, metric = "bias")
tbl1c <- batch1_make_summary_tables( metric_df = metrics_batch1, metric = "power")

#' [ subsetted results]
tbl1d <- batch1_make_summary_tables( metric_df = metrics_batch1_sub, metric = "coverage")
tbl1e <- batch1_make_summary_tables( metric_df = metrics_batch1_sub, metric = "bias")
tbl1f <- batch1_make_summary_tables( metric_df = metrics_batch1_sub, metric = "power")

#' [ add median bias tables ]
tbl1b_medbias <- batch1_make_summary_tables( metric_df = metrics_batch1, metric = "median_bias")
tbl1e_medbias <- batch1_make_summary_tables( metric_df = metrics_batch1_sub, metric = "median_bias")
```

```{r batch-1-tables-toggle-modelno-add-nsim, cache = TRUE, echo = FALSE, message = FALSE}

```


```{r batch-2-tables-unformatted, cache = TRUE, echo = FALSE, message = FALSE}
#' -------------------------------------------------------------------------- #
#' [ Batch 2: Binary Y, continuous X ]
#' -------------------------------------------------------------------------- #
tbl2a <- batch2_make_summary_tables( metric_df = metrics_batch2, metric = "coverage")
tbl2b <- batch2_make_summary_tables( metric_df = metrics_batch2, metric = "bias")
tbl2c <- batch2_make_summary_tables( metric_df = metrics_batch2, metric = "power")
tbl2d <- batch2_make_summary_tables( metric_df = metrics_batch2_sub, metric = "coverage")
tbl2e <- batch2_make_summary_tables( metric_df = metrics_batch2_sub, metric = "bias")
tbl2f <- batch2_make_summary_tables( metric_df = metrics_batch2_sub, metric = "power")
tbl2f_nsim <- batch2_make_summary_tables( metric_df = metrics_batch2_sub, metric = "nsim")
tbl2b_medbias <- batch2_make_summary_tables( metric_df = metrics_batch2, metric = "median_bias")
tbl2e_medbias <- batch2_make_summary_tables( metric_df = metrics_batch2_sub, metric = "median_bias")

#' [ Get average number of simulations per method in subsetted simulations for batch 2 ] 
nsims_batch2_subset <- batch1_make_summary_tables( metric_df = metrics_batch2_sub, metric = "nsim")
batch2_nsim_col <- get_nsim_col( tbl_nsim = nsims_batch2_subset )

#' [ Format large bias values to show ">1000" or "<1000" ] 
col_names_to_truncate <- c("CR_adj", "CR_un", "SBR_adj", "SBR_un", "CAA_model_adj", "CAA_model_un", "CAA_rerand_adj")
col_indices_to_truncate <- which( dimnames( tbl2b )[[2]] %in% col_names_to_truncate )

tbl2b_formatted <- tbl2b;
tbl2b_formatted[, col_indices_to_truncate ] <- apply( tbl2b[, col_indices_to_truncate ], 2, replace_values )
#' Format large bias values to show ">1000" or "<1000"
col_indices_to_truncate <- which( dimnames( tbl2e )[[2]] %in% col_names_to_truncate )
tbl2e_formatted <- tbl2e;
tbl2e_formatted[, col_indices_to_truncate] <- apply( tbl2e[,col_indices_to_truncate], 2, replace_values )
```

```{r batch-3-tables-unformatted, cache = TRUE, echo = FALSE, message = FALSE}
#' [ Batch 3: Continuous Y, binary X ]
tbl3a <- batch3_make_summary_tables( metric_df = metrics_batch3, metric = "coverage")
tbl3b <- batch3_make_summary_tables( metric_df = metrics_batch3, metric = "bias")
tbl3c <- batch3_make_summary_tables( metric_df = metrics_batch3, metric = "power")
```

```{r batch-4-tables-unformatted, cache = TRUE, echo = FALSE, message = FALSE}
#' [ Batch 4: Continuous Y, continuous X ]
tbl4a <- batch4_make_summary_tables( metric_df = metrics_batch4, metric = "coverage")
tbl4b <- batch4_make_summary_tables( metric_df = metrics_batch4, metric = "bias")
tbl4c <- batch4_make_summary_tables( metric_df = metrics_batch4, metric = "power")
```


\newpage

# Results {-}

## Batch 1: Binary outcome (Y), binary prognostic factors (X) {-}
### Complete simulation results (5010 simulations)
```{r batch-1-table-settings, cache = TRUE, echo = FALSE, results = 'asis'}

print_modelno <- FALSE #' [ return modelno? ]
ncol_pads <- ifelse( print_modelno, 6, 5 ) #' [ add extra column padding if so ]
if( print_modelno ){
  .col.names.b1 = c("modelno","n", "Pr( Y )", "Pr( X )", "bZ", "bX", "adj", "unadj", "adj", "unadj", "adj", "unadj", "adj");
}else{
    .col.names.b1 = c("n", "Pr( Y )", "Pr( X )", "bZ", "bX", "adj", "unadj", "adj", "unadj", "adj", "unadj", "adj");
}
.align.b1 = c(rep("c", ncol_pads ), rep("r", 6), "c");
.latex_options.b1 = c("striped", "bordered", "hold_position")
.header.randomization.method.b1 = c(" " = ncol_pads, "CR" = 2, "SBR" = 2, "CAA" = 2, "CAA" = 1);
.header.analysis.method.b1 = c(" " = ncol_pads, "Model-based" = 6, "Rerandomization" = 1);
.batch.labels <- paste0("Table ", 1, c("a", "b", "c", "d", "e", "f"), 
                        ": (Binary Y, binary X) ",
                        c("Coverage probability", "Bias", "Power"))
.linesep = kable_booktabs_linesep( nlines = 6 )

```

```{r batch-1-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
if( print_modelno ){
  tbl1a %>% kable( caption = .batch.labels[ 1 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
}else{
  tbl1a[,-1] %>% kable( caption = .batch.labels[ 1 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
}

```
\newpage

\newpage
```{r batch-1-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1b %>%
kable( caption = .batch.labels[ 2 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```
\newpage
```{r batch-1-median-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1b_medbias %>%
kable( caption = "Table 1b(i): (Binary Y, binary X) Median bias", row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )

```

\newpage
```{r batch-1-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1c %>%
  kable( caption = .batch.labels[ 3 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```

\newpage
### Subsetted simulation results (simulations without non-complete separation)
```{r batch-1-subset-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1d %>%
kable( caption = .batch.labels[ 4 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```

\newpage
```{r batch-1-subset-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1e %>%
  kable( caption = .batch.labels[ 5 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```
\newpage
```{r batch-1-subset-median-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1e_medbias %>%
kable( caption = "Table 1e(i): (Binary Y, binary X) Median bias", row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```

\newpage
```{r batch-1-subset-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl1f %>%
  kable( caption = .batch.labels[ 6 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b1, align = .align.b1, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b1, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b1 ) %>%
  add_header_above( .header.analysis.method.b1 )
```


\newpage
## Batch 2: Binary outcome (Y), continuous prognostic factors (X) {-}
```{r batch-2-table-settings, cache = TRUE, echo = FALSE, results = 'asis'}
.col.names.b2 = c("modelno", "n", "Pr( Y )", "exp( bZ )", "exp( bX )", "adj", "unadj", "adj", "unadj", "adj", "unadj", "adj");
.align.b2 = c(rep("c", 5), rep("r", 6), "c");
.latex_options.b2 = c("striped", "bordered", "hold_position")
.header.randomization.method.b2 = c(" " = 5, "CR" = 2, "SBR" = 2, "CAA" = 2, "CAA" = 1);
.header.analysis.method.b2 = c(" " = 5, "Model-based" = 6, "Rerandomization" = 1);

.batch.labels <- paste0("Table ", 2, c("a", "b", "c", "d", "e", "f"), 
                        ": (Binary Y, continuous X) ",
                        c("Coverage probability", "Bias", "Power"))

.linesep = kable_booktabs_linesep( nlines = 6 )
```

### Complete simulation results (5010 simulations)
```{r batch-2-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2a %>%
kable( caption = .batch.labels[ 1 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```

\newpage
```{r batch-2-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2b_formatted %>%
  kable( caption = .batch.labels[ 2 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )

tbl2b_medbias %>%
kable( caption = "Table 2b(i): (Binary Y, continuous X) Median bias"  , row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```

\newpage
```{r batch-2-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2c %>%
  kable( caption = .batch.labels[ 3 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```

\newpage
### Subsetted simulation results (simulations without non-complete separation)
```{r batch-2-subset-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2d %>%
  kable( caption = .batch.labels[ 4 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```

\newpage
```{r batch-2-subset-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2e_formatted %>%
  kable( caption = .batch.labels[ 5 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )

tbl2e_medbias %>%
kable( caption = "Table 2e(i): (Binary Y, continuous X) Median bias"  , row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```

\newpage
```{r batch-2-subset-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl2f %>%
  kable( caption = .batch.labels[ 6 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b2, align = .align.b2, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b2, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b2 ) %>%
  add_header_above( .header.analysis.method.b2 )
```


```{r batch-3-table-settings, cache = TRUE, echo = FALSE, results = 'asis'}
.col.names.b3 = c("modelno", "n", "Pr( X )", "exp( bZ )", "exp( bX )", "adj", "unadj", "adj", "unadj", "adj", "unadj", "adj");
.align.b3 = c(rep("c", 5), rep("r", 6), "c");
.latex_options.b3 = c("striped", "bordered", "hold_position")
.header.randomization.method.b3 = c(" " = 5, "CR" = 2, "SBR" = 2, "CAA" = 2, "CAA" = 1);
.header.analysis.method.b3 = c(" " = 5, "Model-based" = 6, "Rerandomization" = 1);

.batch.labels <- paste0("Table ", 3, c("a", "b", "c", "d", "e", "f"), 
                        ": (Continuous Y, binary X) ",
                        c("Coverage probability", "Bias", "Power"))
.linesep = kable_booktabs_linesep( nlines = 6 )
```

\newpage
## Batch 3: Continuous outcome (Y), binary prognostic factors (X) {-}
```{r batch-3-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
tbl3a %>%
  kable( caption = .batch.labels[ 1 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b3, align = .align.b3, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b3, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b3 ) %>%
  add_header_above( .header.analysis.method.b3 )
```


```{r batch-3-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl3b %>%
  kable( caption = .batch.labels[ 2 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b3, align = .align.b3, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b3, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b3 ) %>%
  add_header_above( .header.analysis.method.b3 )
```


```{r batch-3-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl3c %>%
kable( caption = .batch.labels[ 3 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b3, align = .align.b3, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b3, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b3 ) %>%
  add_header_above( .header.analysis.method.b3 )
```



```{r batch-4-table-settings, cache = TRUE, echo = FALSE, results = 'asis'}
#' TODO(michael): remove `modelno` and decrement .align.b4, .latex_options.b4, .header.`...` from 4 to 3!
.col.names.b4 = c("modelno","n", "exp( bZ )", "exp( bX )", "adj", "unadj", "adj", "unadj", "adj", "unadj", "adj");
.align.b4 = c(rep("c", 4), rep("r", 6), "c");
.latex_options.b4 = c("striped", "bordered", "hold_position");
.header.randomization.method.b4 = c(" " = 4, "CR" = 2, "SBR" = 2, "CAA" = 2, "CAA" = 1);
.header.analysis.method.b4 = c(" " = 4, "Model-based" = 6, "Rerandomization" = 1);

.batch.labels <- paste0("Table ", 4, c("a", "b", "c", "d", "e", "f"), 
                        ": (Continuous Y, continuous X) ",
                        c("Coverage probability", "Bias", "Power"))
.linesep = kable_booktabs_linesep( nlines = 6 )
```

\newpage
## Batch 4: Continuous outcome (Y), continuous prognostic factors (X) {-}
```{r batch-4-coverage-table, cache = TRUE, echo = FALSE, results='asis'}
tbl4a %>%
kable( caption = .batch.labels[ 1 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b4, align = .align.b4, booktabs = TRUE, linesep = .linesep ) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b4, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b4 ) %>%
  add_header_above( .header.analysis.method.b4 )
```


```{r batch-4-bias-table, cache = TRUE, echo = FALSE, results='asis'}
tbl4b %>%
kable( caption = .batch.labels[ 2 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b4, align = .align.b4, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b4, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b4 ) %>%
  add_header_above( .header.analysis.method.b4 )
```


```{r batch-4-power-table, cache = TRUE, echo = FALSE, results='asis'}
tbl4c %>%
kable( caption = .batch.labels[ 3 ], row.names = FALSE, longtable = TRUE,
       col.names = .col.names.b4, align = .align.b4, booktabs = TRUE, linesep = .linesep) %>%
  kable_styling( font_size = 7, latex_options = .latex_options.b4, full_width = FALSE ) %>%
  add_header_above( .header.randomization.method.b4 ) %>%
  add_header_above( .header.analysis.method.b4 )
```
